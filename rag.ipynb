{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (0.2.7)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (0.2.7)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (0.2.18)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (0.1.85)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user-pc\\appdata\\roaming\\python\\python312\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-community langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main_Page\n",
      "Getting_Started\n",
      "Personal_Tricorder\n",
      "The_Player\n",
      "Stars\n",
      "Crafting\n",
      "Combat\n",
      "Weapons\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community import embeddings\n",
    "\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings # change model and embedding #c1\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# model_local = ChatOllama(model=\"mistral\") #c1\n",
    "model_local = ChatOpenAI(   \n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature = 1\n",
    "    )\n",
    "\n",
    "# 1. Split data into chunks\n",
    "urls = [\n",
    "    \"https://frackinuniverse.miraheze.org/wiki/Main_Page\",\n",
    "    \"https://frackinuniverse.miraheze.org/wiki/Getting_Started\", \n",
    "    \"https://frackinuniverse.miraheze.org/wiki/Personal_Tricorder\",\n",
    "    \"https://frackinuniverse.miraheze.org/wiki/The_Player\",\n",
    "    \"https://frackinuniverse.miraheze.org/wiki/Stars\",\n",
    "    \"https://frackinuniverse.miraheze.org/wiki/Crafting\",\n",
    "    \"https://frackinuniverse.miraheze.org/wiki/Combat\",\n",
    "    \"https://frackinuniverse.miraheze.org/wiki/Weapons\"\n",
    "]\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# extract page name\n",
    "for item in docs_list:\n",
    "    full_url = item.metadata.get(\"source\")\n",
    "    parsed_url = urlparse(full_url)\n",
    "    page_name = unquote(parsed_url.path.split('/')[-1])\n",
    "\n",
    "    item.metadata[\"id\"] = page_name\n",
    "    print(item.metadata[\"id\"])\n",
    "\n",
    "# TODO: experiment with chunk size\n",
    "\n",
    "# text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=7500, chunk_overlap=100)\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=200)\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your question. Type 'exit' to end the program.\n",
      "\n",
      "########\n",
      "embed: nomic embed text\n",
      "\n",
      "\n",
      "\n",
      "*********************\n",
      "['Personal_Tricorder', 'Personal_Tricorder', 'Personal_Tricorder', 'Personal_Tricorder']\n",
      "The features of the Personal Tricorder include:\n",
      "\n",
      "1. **Shift + left-click**: Opens the Research interface to unlock recipes for crafting new items.\n",
      "\n",
      "2. **Left-click**: Opens a menu with:\n",
      "   - Information about the player, including bonuses/penalties by race, resistances to damage types, and temporary immunities.\n",
      "   - GPS information about the current planet, such as weather, gravity, biomes, and surface dungeons.\n",
      "   - Tool to create mobility Techs like Microsphere or Phase Sprint, and equip them.\n",
      "   - Tool to refuel your Mech.\n",
      "   - Tool to replace weapons, thrusters, etc. on your Mech.\n",
      "   - Tool to upgrade all weapons/armor and tools up to their maximum supported tier.\n",
      "   - Codex reader that is more convenient than the usual codex reader in Starbound.\n",
      "\n",
      "3. **Right-click**: Opens the list of Tutorial quests, which can be accepted without visiting NPCs and provide guidance and rewards.\n",
      "\n",
      "4. **Shift + right-click**: Allows configuration of the Matter Manipulator, enabling:\n",
      "   - Temporary reduction of mining area size (e.g., to 3x3 or 2x2) to avoid accidental block removal.\n",
      "   - Temporary disabling of liquid collection.\n",
      "   - Temporary replacement of certain functions of the Matter Manipulator with other tools or weapons.\n",
      "   - Replacement of the basic Matter Manipulator with a more advanced version.\n"
     ]
    }
   ],
   "source": [
    "# 2. Convert documents to Embeddings and store them\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding= OllamaEmbeddings(model='nomic-embed-text'),\n",
    ")\n",
    "\n",
    "# using openAI embeddings\n",
    "vectorstore_openai = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-openai\",\n",
    "    embedding= OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "# print(retriever)\n",
    "retriever_openai = vectorstore_openai.as_retriever()\n",
    "\n",
    "def retrieve_and_format(query):\n",
    "    relevant_docs = retriever.invoke(query)\n",
    "    print('\\n\\n*********************')\n",
    "    print([doc.metadata.get(\"id\") for doc in relevant_docs])\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "\n",
    "# question = \"List out all one-handed melee weapons\"\n",
    "question = \"what are the features of the personal tricorder?\"\n",
    "exit_keyword = \"exit\"\n",
    "print(f\"Enter your question. Type '{exit_keyword}' to end the program.\")\n",
    "\n",
    "# 4. After RAG\n",
    "print(\"\\n########\\nembed: nomic embed text\\n\")\n",
    "rag_template = \"\"\"Answer the question based only on the following context. If the information is not in the context, say you don't have that information.\n",
    ":\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_template)\n",
    "rag_chain = (\n",
    "    {\"context\": RunnableLambda(retrieve_and_format), \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(rag_chain.invoke(question))\n",
    "\n",
    "# print(\"\\n########\\nembed: open ai\\n\")\n",
    "# rag_chain_openai = (\n",
    "#     {\"context\": retriever_openai, \"question\": RunnablePassthrough()}\n",
    "#     | rag_prompt\n",
    "#     | model_local\n",
    "#     | StrOutputParser()\n",
    "# )\n",
    "# print(rag_chain_openai.invoke(question))\n",
    "\n",
    "# while True:\n",
    "    # user_question = input(\"\\nHuman: \").strip()\n",
    "\n",
    "    # if user_question.lower() == exit_keyword.lower():\n",
    "    #     print(\"Exiting the program. Goodbye!\")\n",
    "    #     break\n",
    "\n",
    "    # if user_question:\n",
    "    #     print(\"\\nProcessing your question...\\n\")\n",
    "    #     nomic_response = rag_chain.invoke(user_question)\n",
    "    #     openai_response = rag_chain_openai.invoke(user_question)\n",
    "    #     print(\"====== Nomic Answer======:\\n \",nomic_response)\n",
    "    #     print(\"\\n====== OpenAI Answer ======\\n\",openai_response)\n",
    "    # else:\n",
    "    #     print(\"Please enter a valid question\")\n",
    "\n",
    "# loader = PyPDFLoader(\"Ollama.pdf\")\n",
    "# doc_splits = loader.load_and_split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User-PC\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community import embeddings\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "def process_input(urls, question):\n",
    "    model_local = ChatOllama(model=\"mistral\")\n",
    "    \n",
    "    # Convert string of URLs to list\n",
    "    urls_list = urls.split(\"\\n\")\n",
    "    docs = [WebBaseLoader(url).load() for url in urls_list]\n",
    "    docs_list = [item for sublist in docs for item in sublist]\n",
    "    \n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=200)\n",
    "    doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=doc_splits,\n",
    "        collection_name=\"rag-chroma\",\n",
    "        embedding=embeddings.ollama.OllamaEmbeddings(model='nomic-embed-text'),\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    after_rag_template = \"\"\"Answer the question based only on the following context (If the information is not in the context, say you don't have that information):\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    after_rag_prompt = ChatPromptTemplate.from_template(after_rag_template)\n",
    "    after_rag_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | after_rag_prompt\n",
    "        | model_local\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return after_rag_chain.invoke(question)\n",
    "\n",
    "# Define Gradio interface\n",
    "iface = gr.Interface(fn=process_input,\n",
    "                     inputs=[gr.Textbox(label=\"Enter URLs separated by new lines\"), gr.Textbox(label=\"Question\")],\n",
    "                     outputs=\"text\",\n",
    "                     title=\"Document Query with Ollama\",\n",
    "                     description=\"Enter URLs and a question to query the documents.\")\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
